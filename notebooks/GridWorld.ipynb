{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridWorld Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ReinforcementLearning.FiniteMarkovDecisionProcesses as MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " 15.0   1.0   2.0   3.0\n",
       "  4.0   5.0   6.0   7.0\n",
       "  8.0   9.0  10.0  11.0\n",
       " 12.0  13.0  14.0  15.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function V_to_matrix_form(V)\n",
    "    VV = Matrix{Float64}(undef, 4, 4)\n",
    "    VV[1,1] = V[15]\n",
    "    for i = 1:14\n",
    "        k = div(i,4)\n",
    "        ‚Ñì = rem(i,4)\n",
    "        VV[k+1, ‚Ñì+1] = V[i]\n",
    "    end\n",
    "    VV[4,4] = VV[1,1]\n",
    "    return VV\n",
    "end\n",
    "\n",
    "V_test = 1:15\n",
    "V_to_matrix_form(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üë'  '‚Üê'\n",
       " '‚Üì'  '‚Üí'  '‚Üê'  '‚Üê'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚Üë'\n",
       " '‚Üí'  '‚Üì'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function action_to_char(a)\n",
    "    if a == 1 # up\n",
    "        return '‚Üë'\n",
    "    elseif a == 2 # down\n",
    "        return '‚Üì'\n",
    "    elseif a == 3 # right\n",
    "        return '‚Üí'\n",
    "    elseif a == 4 # left\n",
    "        return '‚Üê'\n",
    "    else\n",
    "        return '?'\n",
    "    end\n",
    "end\n",
    "\n",
    "function P_to_matrix_form(P)\n",
    "    PP = Matrix{Char}(undef, 4, 4)\n",
    "    PP[1,1] = '‚ñà'\n",
    "    for i = 1:14\n",
    "        k = div(i,4)\n",
    "        ‚Ñì = rem(i,4)\n",
    "        PP[k+1, ‚Ñì+1] = action_to_char(P[i])\n",
    "    end\n",
    "    PP[4,4] = '‚ñà'\n",
    "    return PP\n",
    "end\n",
    "\n",
    "P_test = rand(1:4, 15)\n",
    "P_to_matrix_form(P_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states = [\n",
    "    # 1 (up)  2 (down)  3 (right)  4 (left) \n",
    "      1       5         2         15         #  1\n",
    "      2       6         3          1         #  2 \n",
    "      3       7         3          2         #  3\n",
    "     15       8         5          4         #  4\n",
    "      1       9         6          4         #  5\n",
    "      2      10         7          5         #  6\n",
    "      3      11         7          6         #  7\n",
    "      4      12         9          8         #  8\n",
    "      5      13        10          8         #  9\n",
    "      6      14        11          9         # 10\n",
    "      7      15        11         10         # 11\n",
    "      8      12        13         12         # 12\n",
    "      9      13        14         12         # 13\n",
    "     10      14        15         13         # 14\n",
    "     15      15        15         15         # 15\n",
    "]\n",
    "\n",
    "rewards = -1*ones(size(next_states))\n",
    "rewards[15, :] .= 0\n",
    "\n",
    "mdp = MDP.DeterministicFiniteMDP((s,a)->next_states[s, a], (s,a)->rewards[s, a], 4, 15, 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP: Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = 0.25*ones(size(next_states)...);  # Vector{Int64}(undef, size(next_states, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "V[1] = 0\n",
    "\n",
    "iters_no, converged = MDP.dp_evaluate_policy!(V, Q, mdp, policy, 1.0; tol = 1e-4, maxiter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       "   0.0  -14.0  -20.0  -22.0\n",
       " -14.0  -18.0  -20.0  -20.0\n",
       " -20.0  -20.0  -18.0  -14.0\n",
       " -22.0  -20.0  -14.0    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_dp_random_policy = copy(V)\n",
    "V_to_matrix_form(round.(V_dp_random_policy; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üê'\n",
       " '‚Üë'  '‚Üë'  '‚Üì'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üí'  '‚Üì'\n",
       " '‚Üë'  '‚Üí'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = MDP.create_P_from_Q(Q)\n",
    "MDP.P_from_Q!(P, Q)\n",
    "\n",
    "P_to_matrix_form(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP: Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = rand(1:4, size(next_states, 1));\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "V[1] = 0\n",
    "\n",
    "converged = false\n",
    "iters_no = 100\n",
    "for i = 1:iters_no\n",
    "    MDP.dp_evaluate_policy!(V, Q, mdp, P, 1.0; tol = 1e-4, maxiter = 5)\n",
    "    modified = MDP.P_from_Q!(P, Q)\n",
    "    if !modified\n",
    "        converged = true\n",
    "        iters_no = i\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "(iters_no, converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üì'  '‚Üì'\n",
       " '‚Üë'  '‚Üí'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P_dp_optimal = copy(P)\n",
    "P_to_matrix_form(P_dp_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       "  0.0  -1.0  -2.0  -3.0\n",
       " -1.0  -2.0  -3.0  -2.0\n",
       " -2.0  -3.0  -2.0  -1.0\n",
       " -3.0  -2.0  -1.0   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_dp_optimal = copy(V)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Karlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MK: Policy Evaluation (Stochastic Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.25 * ones(size(next_states)...)\n",
    "simulator = MDP.create_simulator(mdp, P)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -14.98  -21.25  -23.43\n",
       " -15.06  -19.06  -20.96  -21.15\n",
       " -20.87  -20.83  -18.77  -15.08\n",
       " -22.89  -20.98  -14.93  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MDP.V_from_Q!(V, Q, P)\n",
    "V_mk_random_policy = copy(V)\n",
    "V_to_matrix_form(round.(V_mk_random_policy; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     0.98  1.25    1.43\n",
       "   1.06  1.06  0.96    1.15\n",
       "   0.87  0.83  0.77    1.08\n",
       "   0.9   0.98  0.93  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_to_matrix_form(round.(V_dp_random_policy .- V_mk_random_policy; digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MK: Policy Evaluation (Deterministic Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùê© = rand(1:4, size(next_states, 1))\n",
    "simulator = MDP.create_simulator(mdp, ùê©, 0.1)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -69.44  -94.55  -90.47\n",
       " -70.26  -93.08  -94.0   -92.0\n",
       " -99.06  -97.24  -99.95  -69.62\n",
       " -96.04  -97.23  -71.78  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.V_from_Q!(V, Q, P)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MK: Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùê© = rand(1:4, size(next_states, 1))\n",
    "simulator = MDP.create_simulator(mdp, ùê©, 0.05)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "converged = false\n",
    "for i = 1:1000\n",
    "    MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 1000)\n",
    "    MDP.P_from_Q!(ùê©, Q)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15√ó4 Matrix{Float64}:\n",
       "  -3.25   -4.4       -4.0    -2.0\n",
       "  -4.0    -5.33333   -5.25   -3.05985\n",
       " NaN      -6.0       -5.0    -4.13793\n",
       "  -2.0    -4.0       -4.0    -3.0\n",
       "  -3.1   NaN         -5.0   NaN\n",
       " NaN     NaN         -6.0    -4.0\n",
       "  -5.0   NaN        NaN     NaN\n",
       "  -3.0   NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN\n",
       " NaN     NaN        NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -2.0   -3.06   -4.14\n",
       "  -2.0   -3.1   -4.0    -5.0\n",
       "  -3.0  NaN    NaN     NaN\n",
       " NaN    NaN    NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.V_from_Q!(V, Q, ùê©)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = MDP.create_simulator(mdp, ùê©, 0.05)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "converged = false\n",
    "for i = 1:1000\n",
    "    MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 10000)\n",
    "    MDP.P_from_Q!(ùê©, Q)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15√ó4 Matrix{Float64}:\n",
       "  -3.125     -4.19091   -4.10753   -2.0\n",
       "  -4.13115   -5.24      -5.14754   -3.06828\n",
       "  -5.14286   -4.125     -5.14286   -4.14049\n",
       "  -2.0       -4.08      -4.16667   -3.17143\n",
       "  -3.1055    -5.0       -5.0       -3.0\n",
       " NaN         -6.0       -4.0       -4.2\n",
       "  -5.0       -3.06061  NaN        NaN\n",
       "  -3.0      NaN         -5.0      NaN\n",
       "  -4.0      NaN        NaN        NaN\n",
       "  -5.0      NaN        NaN        NaN\n",
       "  -4.0       -2.0      NaN        NaN\n",
       " NaN        NaN        NaN        NaN\n",
       " NaN        NaN        NaN        NaN\n",
       " NaN        NaN        NaN        NaN\n",
       " NaN        NaN        NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -2.0   -3.07   -4.12\n",
       "  -2.0   -3.0   -4.0    -3.06\n",
       "  -3.0   -4.0   -5.0    -2.0\n",
       " NaN    NaN    NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.V_from_Q!(V, Q, ùê©)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üì'\n",
       " '‚Üë'  '‚Üê'  '‚Üí'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.P_from_Q!(ùê©, Q)\n",
    "P_to_matrix_form(ùê©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Int64}:\n",
       " 4\n",
       " 4\n",
       " 2\n",
       " 1\n",
       " 4\n",
       " 3\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ùê©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15√ó4 Matrix{Float64}:\n",
       "  -3.125     -4.19091   -4.10753   -2.0\n",
       "  -4.13115   -5.24      -5.14754   -3.06828\n",
       "  -5.14286   -4.125     -5.14286   -4.14049\n",
       "  -2.0       -4.08      -4.16667   -3.17143\n",
       "  -3.1055    -5.0       -5.0       -3.0\n",
       " NaN         -6.0       -4.0       -4.2\n",
       "  -5.0       -3.06061  NaN        NaN\n",
       "  -3.0      NaN         -5.0      NaN\n",
       "  -4.0      NaN        NaN        NaN\n",
       "  -5.0      NaN        NaN        NaN\n",
       "  -4.0       -2.0      NaN        NaN\n",
       " NaN        NaN        NaN        NaN\n",
       " NaN        NaN        NaN        NaN\n",
       " NaN        NaN        NaN        NaN\n",
       " NaN        NaN        NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üì'  '‚Üì'\n",
       " '‚Üë'  '‚Üí'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P_to_matrix_form(P_dp_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üì'\n",
       " '‚Üë'  '‚Üê'  '‚Üí'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P_to_matrix_form(ùê©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
