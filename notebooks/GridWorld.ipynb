{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridWorld Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ReinforcementLearning.FiniteMarkovDecisionProcesses as MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " 15.0   1.0   2.0   3.0\n",
       "  4.0   5.0   6.0   7.0\n",
       "  8.0   9.0  10.0  11.0\n",
       " 12.0  13.0  14.0  15.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function V_to_matrix_form(V)\n",
    "    VV = Matrix{Float64}(undef, 4, 4)\n",
    "    VV[1,1] = V[15]\n",
    "    for i = 1:14\n",
    "        k = div(i,4)\n",
    "        ‚Ñì = rem(i,4)\n",
    "        VV[k+1, ‚Ñì+1] = V[i]\n",
    "    end\n",
    "    VV[4,4] = VV[1,1]\n",
    "    return VV\n",
    "end\n",
    "\n",
    "V_test = 1:15\n",
    "V_to_matrix_form(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üì'  '‚Üë'  '‚Üê'\n",
       " '‚Üë'  '‚Üì'  '‚Üí'  '‚Üë'\n",
       " '‚Üê'  '‚Üí'  '‚Üì'  '‚Üí'\n",
       " '‚Üí'  '‚Üì'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function action_to_char(a)\n",
    "    if a == 1 # up\n",
    "        return '‚Üë'\n",
    "    elseif a == 2 # down\n",
    "        return '‚Üì'\n",
    "    elseif a == 3 # right\n",
    "        return '‚Üí'\n",
    "    elseif a == 4 # left\n",
    "        return '‚Üê'\n",
    "    else\n",
    "        return '?'\n",
    "    end\n",
    "end\n",
    "\n",
    "function P_to_matrix_form(P)\n",
    "    PP = Matrix{Char}(undef, 4, 4)\n",
    "    PP[1,1] = '‚ñà'\n",
    "    for i = 1:14\n",
    "        k = div(i,4)\n",
    "        ‚Ñì = rem(i,4)\n",
    "        PP[k+1, ‚Ñì+1] = action_to_char(P[i])\n",
    "    end\n",
    "    PP[4,4] = '‚ñà'\n",
    "    return PP\n",
    "end\n",
    "\n",
    "P_test = rand(1:4, 15)\n",
    "P_to_matrix_form(P_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states = [\n",
    "    # 1 (up)  2 (down)  3 (right)  4 (left) \n",
    "      1       5         2         15         #  1\n",
    "      2       6         3          1         #  2 \n",
    "      3       7         3          2         #  3\n",
    "     15       8         5          4         #  4\n",
    "      1       9         6          4         #  5\n",
    "      2      10         7          5         #  6\n",
    "      3      11         7          6         #  7\n",
    "      4      12         9          8         #  8\n",
    "      5      13        10          8         #  9\n",
    "      6      14        11          9         # 10\n",
    "      7      15        11         10         # 11\n",
    "      8      12        13         12         # 12\n",
    "      9      13        14         12         # 13\n",
    "     10      14        15         13         # 14\n",
    "     15      15        15         15         # 15\n",
    "]\n",
    "\n",
    "rewards = -1*ones(size(next_states))\n",
    "rewards[15, :] .= 0\n",
    "\n",
    "mdp = MDP.DeterministicFiniteMDP((s,a)->next_states[s, a], (s,a)->rewards[s, a], 4, 15, 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP: Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = 0.25*ones(size(next_states)...);  # Vector{Int64}(undef, size(next_states, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "V[1] = 0\n",
    "\n",
    "iters_no, converged = MDP.dp_evaluate_policy!(V, Q, mdp, policy, 1.0; tol = 1e-4, maxiter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       "   0.0  -14.0  -20.0  -22.0\n",
       " -14.0  -18.0  -20.0  -20.0\n",
       " -20.0  -20.0  -18.0  -14.0\n",
       " -22.0  -20.0  -14.0    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_dp_random_policy = copy(V)\n",
    "V_to_matrix_form(round.(V_dp_random_policy; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üì'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üí'  '‚Üì'\n",
       " '‚Üë'  '‚Üí'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = MDP.create_P_from_Q(Q)\n",
    "MDP.P_from_Q!(P, Q)\n",
    "\n",
    "P_to_matrix_form(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP: Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = rand(1:4, size(next_states, 1));\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "V[1] = 0\n",
    "\n",
    "converged = false\n",
    "iters_no = 100\n",
    "for i = 1:iters_no\n",
    "    MDP.dp_evaluate_policy!(V, Q, mdp, P, 1.0; tol = 1e-4, maxiter = 5)\n",
    "    modified = MDP.P_from_Q!(P, Q)\n",
    "    if !modified\n",
    "        converged = true\n",
    "        iters_no = i\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "(iters_no, converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üë'  '‚Üì'\n",
       " '‚Üë'  '‚Üë'  '‚Üì'  '‚Üì'\n",
       " '‚Üë'  '‚Üí'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P_dp_optimal = copy(P)\n",
    "P_to_matrix_form(P_dp_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       "  0.0  -1.0  -2.0  -3.0\n",
       " -1.0  -2.0  -3.0  -2.0\n",
       " -2.0  -3.0  -2.0  -1.0\n",
       " -3.0  -2.0  -1.0   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_dp_optimal = copy(V)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Karlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MK: Policy Evaluation (Stochastic Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.25 * ones(size(next_states)...)\n",
    "simulator = MDP.create_simulator(mdp, P)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -15.02  -20.93  -22.98\n",
       " -14.68  -18.89  -21.05  -20.95\n",
       " -21.01  -20.92  -19.11  -15.24\n",
       " -23.0   -20.65  -15.03  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MDP.V_from_Q!(V, Q, P)\n",
    "V_mk_random_policy = copy(V)\n",
    "V_to_matrix_form(round.(V_mk_random_policy; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     1.02  0.94    0.98\n",
       "   0.68  0.89  1.05    0.95\n",
       "   1.01  0.92  1.11    1.24\n",
       "   1.0   0.65  1.03  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_to_matrix_form(round.(V_dp_random_policy .- V_mk_random_policy; digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MK: Policy Evaluation (Deterministic Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùê© = rand(1:4, size(next_states, 1))\n",
    "simulator = MDP.create_simulator(mdp, ùê©, 0.1)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       "  NaN     -152.36  -219.66  -226.95\n",
       " -164.27  -207.8   -216.77  -227.1\n",
       " -217.66  -162.35  -168.77  -187.86\n",
       " -171.99   -97.41   -77.13   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.V_from_Q!(V, Q, P)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MK: Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùê© = rand(1:4, size(next_states, 1))\n",
    "simulator = MDP.create_simulator(mdp, ùê©, 0.05)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "converged = false\n",
    "for i = 1:1000\n",
    "    MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 1000)\n",
    "    MDP.P_from_Q!(ùê©, Q)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15√ó4 Matrix{Float64}:\n",
       "  -3.0       -4.0       -4.0       -2.0\n",
       " NaN         -5.0      NaN         -3.0137\n",
       "  -5.0       -4.17568  NaN         -4.0\n",
       "  -2.0       -4.0       -4.0       -3.0\n",
       "  -3.07857   -5.0       -5.0       -3.0\n",
       "  -4.0       -4.0      NaN         -4.10345\n",
       "  -5.0       -3.06897  NaN         -5.0\n",
       "  -3.06993   -5.0       -5.0      NaN\n",
       " NaN         -4.0       -4.0       -4.13514\n",
       "  -5.0       -3.0       -3.15      -7.0\n",
       "  -4.0       -2.0       -3.0       -4.0\n",
       "  -4.0      NaN         -4.15714   -6.0\n",
       "  -5.0      NaN         -3.06818   -5.0\n",
       "  -4.0       -3.0       -2.0       -4.0\n",
       " NaN        NaN        NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -2.0   -3.01   -4.0\n",
       "  -2.0   -3.0   -4.0    -3.07\n",
       "  -3.07  -4.0   -3.0    -2.0\n",
       "  -4.0   -3.07  -2.0   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.V_from_Q!(V, Q, ùê©)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = MDP.create_simulator(mdp, ùê©, 0.05)\n",
    "V, Q = MDP.allocate_V_and_Q(mdp)\n",
    "converged = false\n",
    "for i = 1:1000\n",
    "    MDP.mk_evaluate_policy!(Q, simulator, 1.0; maxiter = 10000)\n",
    "    MDP.P_from_Q!(ùê©, Q)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15√ó4 Matrix{Float64}:\n",
       "  -3.0       -4.2069    -4.05556   -2.0\n",
       "  -4.0       -5.06667   -5.2       -3.0571\n",
       "  -5.09091   -4.13919   -5.21429   -4.0\n",
       "  -2.0       -4.08824   -4.22449   -3.0566\n",
       "  -3.11111   -5.15      -5.0       -3.06383\n",
       "  -4.12342   -4.0       -4.14286   -4.1\n",
       "  -5.08696   -3.06881   -4.16129   -5.08696\n",
       "  -3.07317   -5.30769   -5.25      -4.41667\n",
       "  -4.1317    -4.0       -4.4       -4.30769\n",
       "  -5.0       -3.06739   -3.0       -5.0\n",
       "  -4.11111   -2.0       -3.0       -4.0\n",
       "  -4.14577   -5.2       -4.0       -5.4\n",
       "  -5.0       -4.0       -3.05891   -5.42857\n",
       "  -4.14286   -3.15625   -2.0       -4.07692\n",
       " NaN        NaN        NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Float64}:\n",
       " NaN     -2.0   -3.06   -4.0\n",
       "  -2.0   -3.06  -4.0    -3.07\n",
       "  -3.07  -4.0   -3.0    -2.0\n",
       "  -4.0   -3.06  -2.0   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.V_from_Q!(V, Q, ùê©)\n",
    "V_to_matrix_form(round.(V; digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó4 Matrix{Char}:\n",
       " '‚ñà'  '‚Üê'  '‚Üê'  '‚Üê'\n",
       " '‚Üë'  '‚Üê'  '‚Üì'  '‚Üì'\n",
       " '‚Üë'  '‚Üì'  '‚Üí'  '‚Üì'\n",
       " '‚Üí'  '‚Üí'  '‚Üí'  '‚ñà'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDP.P_from_Q!(ùê©, Q)\n",
    "P_to_matrix_form(ùê©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
